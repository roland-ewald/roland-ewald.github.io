% This file was created with JabRef 2.8.1.
% Encoding: Cp1252

@PROCEEDINGS{Barros2014,
  title = {Proceedings of the 7th International ICST Conference on Simulation
	Tools and Techniques},
  year = {2014},
  online = {http://dl.acm.org/citation.cfm?id=2643094},  
  author = {Barros, Fernando and Perumalla, Kalyan and Ewald, Roland (eds.)},
  editor = {Barros, Fernando and Perumalla, Kalyan and Ewald, Roland},  
  publisher = {ICST},
  booktitle = {ICST},
  note = {Proceedings},
}

@MISC{Batt2006,
  author = {Batt, Gregory and Bradley, Jeremy T. and Ewald, Roland and Fages,
	Francois and Hermans, Holger and Hillston, Jane and Kemper, Peter
	and Martens, Alke and Mosterman, Pieter and Nielson, Flemming and
	Sokolsky, Oleg and Uhrmacher, Adelinde M.},
  title = {06161 Working Groups' Report: The Challlenge of Combining Simulation
	and Verification},
  year = {2006},
  note = {Report},
  address = {Dagstuhl, Germany},
  booktitle = {Simulation and Verification of Dynamic Systems, Dagstuhl Seminar
	Proceedings},
  editor = {Nicol, David M. and Priami, Corrado and Nielson, Hanne R. and Uhrmacher,
	Adelinde M.},
  number = {06161},
  online = {http://drops.dagstuhl.de/opus/volltexte/2006/724},
  publisher = {Internationales Begegnungs- und Forschungszentrum für Informatik
	(IBFI), Schloss Dagstuhl, Germany},
  series = {Dagstuhl Seminar Proceedings},
  url = {http://drops.dagstuhl.de/opus/volltexte/2006/724}
}

@MISC{Bohk2012,
  author = {Bohk, Christina and Ewald, Roland and Rau, Roland},
  title = {Towards a Generalized Subpopulation Support for Stochastic Population
	Projections},
  year = {2012},
  note = {Poster },
  abstract = {Demographic heterogeneity, i.e. differing mortality and fertility
	among subpopulations, is an important issue in stochastic demographic
	forecasting. Common approaches typically use the variables age and
	sex to construct subpopulations, but this might be insufficient and
	induce projection error. Many studies show significant differences
	in mortality and fertility among people with and without migration
	background, but also among people with different level of education
	or country of origin. So far, our model projects the autochthonous
	population, immigrants, emigrants, and their descendant generations
	with separate mortality and fertility. Hence, the subpopulations
	are build with the variables age, sex, and migration status. In this
	paper, we extend the model so that a forecaster can project an unlimited
	number of subpopulations. Next to age, sex, and migration background,
	a forecaster can use other characteristics like reason of migration
	or employment to construct subpopulations, and thus to increase projection
	accuracy.},
  abstractonline = {http://informs-sim.org/wsc12papers/includes/files/pos136.pdf},
  booktitle = {Proceedings of the 2012 Winter Simulation Conference}
}

@INPROCEEDINGS{Bohk2009,
  author = {Bohk, Christina and Ewald, Roland and Uhrmacher, Adelinde M.},
  title = {Probabilistic Population Projection with James II},
  booktitle = {Proceedings of the 2009 Winter Simulation Conference},
  year = {2009},
  editor = {Rossetti, M. D. and Hill, R. R. and Johansson, B. and Dunkin, A.
	and Ingalls, R. G.},
  pages = {2008--2019},
  publisher = {IEEE Computer Science},
  abstract = {Predicting future populations and their structure is a central theme
	in demography. It is related to public health issues, political decision-making,
	or urban planning. Since these predictions are concerned with the
	evolution of a complex system, they exhibit a considerable uncertainty.
	Accounting for this inherent uncertainty is crucial for subsequent
	decision processes, as it reveals the range of possible outcomes
	and their likelihood. Consequently, probabilistic prediction approaches
	emerged over the past decades. This paper describes the probabilistic
	population projection model (PPPM), a recently developed method that
	allows detailed projections, but has a complex structure and requires
	much input data. We discuss the development of P3J, a tool that helps
	users in managing and executing projections and is built on top of
	the simulation system JAMES II. We outline how even specific tools
	like P3J profit from general-purpose simulation frameworks like JAMES
	II, and illustrate its usage by a simple example.},
  doi = {http://dx.doi.org/10.1109/WSC.2009.5429715},
  online = {http://www.informs-sim.org/wsc09papers/193.pdf}
}

@ARTICLE{Chen2008,
  author = {Chen, Dan and Ewald, Roland and Theodoropoulos, Georgios K. and Minson,
	Robert and Oguara, Ton and Lees, Michael and Logan, Brian and Uhrmacher,
	Adelinde M. },
  title = {Data Access in Distributed Simulations of Multi-agent Systems},
  journal = {Journal of Systems and Software},
  year = {2008},
  volume = {81},
  pages = {2345--2360},
  number = {12},
  month = dec,
  abstract = {Distributed simulation has emerged as an important instrument for
	studying large-scale complex systems. Such systems inherently consist
	of a large number of components, which operate in a large shared
	state space interacting with it in highly dynamic and unpredictable
	ways. Optimising access to the shared state space is crucial for
	achieving efficient simulation executions. Data accesses may take
	two forms: locating data according to a set of attribute value ranges
	(range query) or locating a particular state variable from the given
	identifier (ID query and update). This paper proposes two alternative
	routing approaches, namely the address-based approach, which locates
	data according to their address information, and the range-based
	approach, whose operation is based on looking up attribute value
	range information along the paths to the destinations. The two algorithms
	are discussed and analysed in the context of PDES-MAS, a framework
	for the distributed simulation of multi-agent systems, which uses
	a hierarchical infrastructure to manage the shared state space. The
	paper introduces a generic meta-simulation framework which is used
	to perform a quantitative comparative analysis of the proposed algorithms
	under various circumstances.},
  doi = {10.1016/j.jss.2008.04.041},
  online = {http://dx.doi.org/10.1016/j.jss.2008.04.041}
}

@TECHREPORT{Chen2006,
  author = {Chen, Dan and Ewald, Roland and Theodoropoulos, Georgios K. and Oguara,
	Tonworio},
  title = {Data Management in Distributed Simulation of Complex Systems},
  institution = {University of Birmingham, School of Computer Science},
  year = {2006},
  number = {CSR-06-06},
  month = jul,
  note = {Report},
  abstract = {Distributed simulation has emerged as an important instrument for
	studying large-scale complex systems. Such systems inherently consist
	of a large number of components, which operate in a large shared
	state space interacting with it in highly dynamic and unpredictable
	ways. Optimising access to the enormous shared data is crucial for
	achieving efficient simulation executions. This effort involves two
	major issues, data distribution and data accessing. In this paper,
	we discuss the issues of modelling shared data. We have developed
	a framework for distributed simulation of MAS, which uses a hierarchical
	infrastructure to manage the shared data and facilitate interoperation
	amongst agent simulation models. Our framework aims to reduce the
	cost of accessing shared data by dynamically redistributing shared
	data in the infrastructure according to the access pattern of the
	agent simulation models. Data accesses may take two forms: locating
	data according to a set of attribute value ranges (Range query) locating
	a particular state variable from the given identifier (ID query and
	update). This paper proposes two alternative routing approaches,
	namely the address-based approach, which locates data according to
	their address information, and the range-based approach, whose operation
	is based on looking up attribute value range information along the
	paths to the destinations. The two algorithms are discussed an analysed
	in the context of PDES-MAS, a framework for the distributed simulation
	of multi-agent systems, which uses a hierarchical infrastructure
	to manage the shared state space. The paper introduces a generic
	meta-simulation framework which is used to perform a quantitative
	comparative analysis of the proposed algorithms under various circumstances.},
  booktitle = {Technical Report CSR-06-06, University of Birmingham, School of Computer
	Science},
  online = {ftp://ftp.cs.bham.ac.uk/pub/tech-reports/2006/CSR-06-06.ps.gz},
  preprint = {docs/2006_ChenDan_DataManagement.pdf}
}

@MISC{Engelke2012,
  author = {Engelke, Robert and Ewald, Roland},
  title = {Configuring Simulation Algorithms with ParamILS},
  year = {2012},
  note = {Poster },
  abstract = {Simulation algorithms often expose various numerical parameters, e.g.,
	to control the size of auxiliary data structures or to configure
	certain heuristics. While this allows to fine-tune a simulator to
	a given model, it also makes simulator configuration more complex.
	For example, determining suitable default parameters from a multi-dimensional
	parameter space is challenging, as these parameters shall work well
	on a broad range of models. Instead of manually selecting parameter
	values, the configuration space of a simulation algorithm can also
	be searched automatically. We investigate how well ParamILS (Hutter
	et al. 2009), an iterated local search algorithm for algorithm configuration,
	can be applied to simulation algorithms, and discuss its implementation
	in context of the open-source modeling and simulation framework JAMES
	II.},
  abstractonline = {http://informs-sim.org/wsc12papers/includes/files/pos166.pdf},
  booktitle = {Proceedings of the 2012 Winter Simulation Conference}
}

@INPROCEEDINGS{Ewald2014a,
  author = {Ewald, Roland},
  title = {Using AI Planning to Automate the Performance Analysis of Simulators},
  booktitle = {Proceedings of the 7th International ICST Conference on Simulation
	Tools and Techniques (SIMUTools)},
  year = {2014},
  publisher = {ICST},
  abstract = {Analyzing simulation algorithm performance is cumbersome: execute
	some runs, observe a performance metric, and analyze the results.
	Often, the results motivate follow-up experiments, which in turn
	may lead to additional experiments, and so on. This time-consuming
	and error-prone process can be automated with planning approaches
	from artificial intelligence, making simulator performance analysis
	more convenient and rigorous. This paper introduces ALeSiA, a prototypical
	system for automatic simulator performance analysis. It is independent
	of any specific simulation system and realizes a hypothesis-driven
	approach to evaluate performance.},
  preprint = {docs/2014_Ewald_AIPlanning.pdf},
  slides = {docs/2014_Ewald_AIPlanning_talk.pdf}
}

@PHDTHESIS{Ewald2010Dis,
  author = {Ewald, Roland},
  title = {Automatic Algorithm Selection for Complex Simulation Problems},
  year = {2011},
  note = {PhD Thesis},
  abstract = {To select the most suitable simulation algorithm for a given task
	is often difficult. This is due to intricate interactions between
	model features, implementation details, and runtime environment,
	which may strongly affect the overall performance. An automated selection
	of simulation algorithms supports users in setting up simulation
	experiments, without demanding expert knowledge on simulation. The
	first part of the thesis surveys existing approaches to solve the
	algorithm selection problem and discusses techniques to analyze simulation
	algorithm performance. A unified categorization of existing algorithm
	selection techniques is worked out, as these stem from various research
	domains (e.g., finance, artificial intelligence). The second part
	introduces a software framework for automatic simulation algorithm
	selection and describes its constituents, as well as their integration
	into the modeling and simulation framework JAMES II. The implemented
	selection mechanisms are able to cope with three situations: a) no
	prior knowledge is available, b) the impact of problem features on
	performance is unknown, and c) a relationship between problem features
	and algorithm performance can be established empirically. An experimental
	evaluation of the developed methods concludes the thesis. It is shown
	that an automated algorithm selection may significantly increase
	the overall performance of a simulation system. Some of the presented
	mechanisms also support the research on simulation methods, as they
	facilitate their development and evaluation.},
  booktitle = {University of Rostock, published by Vieweg + Teubner},
  isbn = {9781420070231},
  online = {http://dx.doi.org/10.1007/978-3-8348-8151-9},
  preprintonline = {http://rosdok.uni-rostock.de/file/rosdok_derivate_000000004804/Dissertation_Ewald_2011.pdf}
}

@MASTERSTHESIS{Ewald2006MSc,
  author = {Ewald, Roland},
  title = {Simulation of Load Balancing Algorithms for Discrete Event Simulations},
  school = {Universit{\"a}t Rostock},
  year = {2006},
  note = {Diploma Thesis},
  abstract = {Efficiently simulating discrete-event models in a parallel and distributed
	manner is a challenging endeavour. On one hand, various factors,
	such as hardware infrastructure or model characteristics, have to
	be considered. On the other hand, there is a wide variety of algorithms
	which address ubproblems of parallel and distributed simulation and
	whose performance depends on the application at hand. This work illustrates
	the resulting difficulties with respect to the development of parallel
	and distributed simulation systems for general purposes. It is reasoned
	to what extent a prior analysis could facilitate this task. Approaches
	to predict the performance of parallel and distributed simulation
	systems are discussed. It is argued that the simulation of such a
	simulation system is a feasible approach. This claim is underpinned
	by implementing SimSim, a sequential simulator to simulate parallel
	and distributed simulation systems. Then, SimSim is used to develop
	a load balancing algorithm for the simulation of PDEVS models. The
	algorithm’s performance is analysed using SimSim. Finally, the predicted
	performance is compared to the real performance of the algorithm
	when running in the simulation system James II.},
  booktitle = {Universität Rostock},
  online = {http://books.google.de/books?hl=de&lr=&id=puqhYJm32Q4C},
  preprint = {docs/2006_Ewald_Diplomarbeit.pdf}
}

@MISC{Ewald2005Studienarbeit,
  author = {Ewald, Roland},
  title = {Modellpartitionierung in JAMES II},
  year = {2005},
  note = {Student's Project},
  abstract = {Modellpartitionierung, also die Zerlegung eines Modells in verschiedene
	Teile, ist eine grundlegende Voraussetzung für die parallel-verteilte
	Ausführung von Simulationen. Zur Unterstützung dieser Funktionalität
	wird ein Framework zur Partitionierung in JAMES II integriert. Anschliessend
	wird ein Partitionierungsalgorithmus für DEVS-Modelle entwickelt
	und getestet.},
  booktitle = {Universität Rostock},
  preprint = {docs/2005_Ewald_Studienarbeit.pdf}
}

@INPROCEEDINGS{Ewald2006,
  author = {Ewald, Roland and Chen, Dan and Theodoropoulos, Georgios K. and Lees,
	Michael and Logan, Brian and Oguara, Ton and Uhrmacher, Adelinde
	M. },
  title = {Performance Analysis of Shared Data Access Algorithms for Distributed
	Simulation of Multi-Agent Systems},
  booktitle = {Proceedings of the 20th ACM/IEEE/SCS Workshop on Principles of Advanced
	and Distributed Simulation (PADS)},
  year = {2006},
  abstract = {Distributed simulation is an important instrument for studying multi-agent
	systems (MAS). Such large scale MAS simulations often have a large
	shared state space. Moreover, the shared state and the access pattern
	of agent simulations both are highly dynamic and unpredictable. Optimising
	access to the shared data is crucial for achieving efficient simulation
	executions. PDES-MAS is a framework for distributed simulation of
	MAS, which uses a hierarchical infrastructure to manage the shared
	data. In order to enable agent simulations to access distributed
	shared data efficiently, this paper proposes two routing algorithms,
	namely the address-based routing and the range-based routing. The
	paper introduces a meta-simulation approach to evaluate the characteristics
	of both solutions and provides a quantitative comparative analysis
	of the proposed algorithms.},
  doi = {10.1109/PADS.2006.29},
  online = {http://dx.doi.org/10.1109/PADS.2006.29},
  url = {http://dx.doi.org/10.1109/PADS.2006.29}
}

@MISC{Ewald2006d,
  author = {Ewald, Roland and Gutzeit, Enrico and Schwanke, Sebastian and Uhrmacher,
	Adelinde and Lange, Christian and Biermann, Susanne and Maus, Carsten},
  title = {Multi-Level Modeling with DEVS - A Critical Inspection and Steps
	Towards a Feasible Approach},
  month = dec,
  year = {2006},
  note = {Poster},
  abstract = {Multi-level modeling means the description of systems at different
	abstraction levels. In Systems Biology, different abstraction levels
	that arise from considering parts of the system at macro (e.g., concentrations)
	and parts of the system at micro (e.g., individual) level are of
	particular interest. Many modelling formalisms allow the modular
	and hierarchical construction of models. Those have often been inspired
	by DEVS and its construction of hierarchical models via the coupling
	of other models, but this type of hierarchy does still not allow
	a direct description of multi-level models, as the composed model
	has no behavior or state of its own. In DEVS, like in other modeling
	formalisms, macro and micro models are constructured as modular entities
	interacting with each other, as if they were equal sub-models. While
	this approach enables the use of established formalisms, it inhibits
	a clear distinction between the levels of abstraction and therefore
	hampers reusability, clearness and expressiveness. To overcome these
	problems, coupled DEVS models have been enriched by newly introduced
	high-level models that serve as a representation of the macro-level.
	Our approach is based on the rhoDEVS modelling formalism, which already
	provides variables structures, ports, and multi-couplings as key
	features. As an additional feature, high-level models may completely
	determine their coupled model's external input and output ports and
	can filter all inputs and outputs. This enables us to translate macro-
	and micro-level events over multiple abstraction levels. Furthermore,
	this behaviour could be very useful for modeling membrane systems.
	We present the realization of this approach in James II and the individual-based
	simulation of the canonical Wnt-Pathway as a sample application,
	in which a high-level model implementing the Gillespie approach serves
	as a particle collision scheduler. Similarly, a high-level model
	could include differential equations, or any other approach to model
	high-level properties of the system at hand. With its ability to
	survey all structural activities going on at the micro-level and
	to directly affect individuals by scheduling own events, the upward
	and downward causation in biological systems is captured. Although
	it looks as if we left DEVS far behind with this extension, it can
	be shown that models based on the extended formalism are still equivalent
	to basic DEVS models. Hence, the DEVS advantages, like modular composition
	of models via coupling, are preserved. Our approach is feasible to
	model any number of abstraction levels and can be coupled to other
	DEVS extensions (including hybrid models). We hope it eases the development
	of spatial biological models, including membranes, compartments and
	multiple abstraction levels.},
  address = {Monterey},
  booktitle = {Proceedings of the 2006 Winter Simulation Conference},
  online = {http://informs-sim.org/wsc06papers/abstracts06/PS2.htm#uhrmachera56060p}
}

@ARTICLE{Ewald2010,
  author = {Ewald, Roland and Himmelspach, Jan and Jeschke, Matthias and Leye,
	Stefan and Uhrmacher, Adelinde M},
  title = {Flexible Experimentation in the Modeling and Simulation Framework
	JAMES II --- Implications for Computational Systems Biology},
  journal = {Briefings in Bioinformatics},
  year = {2010},
  volume = {11},
  pages = {290--300},
  number = {3},
  abstract = {Dry-lab experimentation is increasingly used to complement wet-lab
	experimentation. However, conducting dry-lab experiments is a challenging
	endeavor that requires the combination of diverse techniques. JAMES
	II, a plug-in based open source modeling and simulation framework,
	facilitates the exploitation and configuration of these techniques.
	The different aspects that form an experiment are made explicit to
	facilitate repeatability and reuse. Each of those influences the
	performance and the quality of the simulation experiment. Common
	experimentation pitfalls and current challenges are discussed along
	the way.},
  online = {http://bib.oxfordjournals.org/content/11/3/290.full.pdf+html}
}

@INPROCEEDINGS{Ewald2009b,
  author = {Ewald, Roland and Himmelspach, Jan and Jeschke, Matthias and Leye,
	Stefan and Uhrmacher, Adelinde M},
  title = {Performance Issues in Evaluating Models and Designing Simulation
	Algorithms},
  booktitle = {Proceedings of the 2009 International Workshop on High Performance
	Computational Systems Biology},
  year = {2009},
  pages = {71-80},
  publisher = {IEEE CPS},
  abstract = {The increase and diversity of simulation methods bears witness of
	the need for more efficient discrete event simulations in computational
	biology --- but how efficient are those methods, and how to ensure
	an efficient simulation for a concrete model? As the performance
	of simulation methods depends on the model, the simulator, and the
	infrastructure, general answers to those questions are likely to
	remain illusive; they have to be sought individually and experimentally
	instead. This requires configurable implementations of many algorithms,
	means to define and conduct meaningful experiments on them, and mechanisms
	for storing and analyzing observed performance data. In this paper,
	we first overview basic approaches for improving simulation performance
	and illustrate the challenges when comparing different methods. We
	then argue that providing all the aforementioned components in a
	single tool, in our case the open source modeling and simulation
	framework JAMES II, reveals many synergies in effectively pursuing
	both questions. This is exemplified by presenting results of recent
	studies and introducing a new component to swiftly evaluate simulator
	code changes against previous experimental data.},
  online = {http://dx.doi.org/10.1109/HiBi.2009.16}
}

@INPROCEEDINGS{Ewald2008,
  author = {Ewald, Roland and Himmelspach, Jan and Uhrmacher, Adelinde M. },
  title = {An Algorithm Selection Approach for Simulation Systems},
  booktitle = {Proceedings of the 22nd ACM/IEEE/SCS Workshop on Principles of Advanced
	and Distributed Simulation (PADS)},
  year = {2008},
  volume = {22},
  pages = {91--98},
  address = {Los Alamitos, CA, USA},
  publisher = {IEEE Computer Society},
  abstract = {No simulation algorithm will deliver best performance under all circumstances,
	so simulation systems often offer execution alternatives to choose
	from. This leads to another problem: how is the user supposed to
	know which algorithm to select? The need for an automated selection
	mechanism is often neglected, as many simulation systems are focused
	on specific applications or modeling formalisms and therefore have
	a limited number of expert users. In general-purpose simulation systems
	like JAMES II, an 'intelligent' selection mechanism could help to
	increase the overall performance, especially when users have limited
	knowledge of the underlying algorithms and their implementation(s)(which
	is almost always the case). We describe an approach to integrate
	algorithm selection methods with such systems. Its effectiveness
	is illustrated in conjunction with the 'plug 'n simulate' approach
	of JAMES II.},
  doi = {10.1109/PADS.2008.9},
  online = {http://dx.doi.org/10.1109/PADS.2008.9}
}

@INPROCEEDINGS{Ewald2006b,
  author = {Ewald, Roland and Himmelspach, Jan and Uhrmacher, Adelinde M.},
  title = {A Non-Fragmenting Partitioning Algorithm for Hierarchical Models},
  booktitle = {Proceedings of the 2006 Winter Simulation Conference},
  year = {2006},
  pages = {848--855},
  address = {Monterey, California},
  publisher = {Winter Simulation Conference},
  abstract = {The simulation system James II is aimed at supporting a range of modeling
	formalisms and simulation engines. The partitioning of models is
	essential for distributed simulation. A suitable partition depends
	on model, hardware, and simulation algorithm characteristics. Therefore,
	a partitioning layer has been created in James II which allows to
	plug in partitioning algorithms on demand. Three different partitioning
	algorithms have been implemented. In addition to the well known Kernighan-Lin
	algorithm and a geometric approach, a partitioning algorithm for
	hierarchically structured models has been developed whose performance
	is evaluated.},
  online = {http://www.informs-sim.org/wsc06papers/106.pdf}
}

@INPROCEEDINGS{Ewald2006c,
  author = {Ewald, Roland and Himmelspach, Jan and Uhrmacher, Adelinde M. and
	Chen, Dan and Theodoropoulos, Georgios K. },
  title = {A Simulation Approach to Facilitate Parallel and Distributed Discrete-Event
	Simulator Development},
  booktitle = {Proceedings of the 10th IEEE International Symposium on Distributed
	Simulation and Real Time Applications (DS-RT)},
  year = {2006},
  pages = {209--218},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract = {Efficiently simulating discrete-event models in a parallel and distributed
	manner is a challenging endeavour. On one hand, various factors,
	such as hardware infrastructure or model characteristics, have to
	be considered. On the other hand, there is a wide variety of algorithms
	which address subproblems of parallel and distributed simulation
	and whose performance depends on the application at hand. We illustrate
	the resulting difficulties with respect to the development of parallel
	and distributed simulation systems and argue that the simulation
	of distributed simulation systems is a feasible approach to alleviate
	them. To illustrate this, we introduce SimSim, a sequential simulator
	that allows the simulation of parallel and distributed simulation
	systems. SimSim was used to develop a load balancing algorithm for
	the simulation of PDEVS models. The algorithm's performance is analysed
	using SimSim and the predicted performance is compared to the performance
	of its implementation in the simulation system James II.},
  doi = {10.1109/DS-RT.2006.5},
  online = {http://dx.doi.org/10.1109/DS-RT.2006.5},
  url = {http://dx.doi.org/10.1109/DS-RT.2006.5}
}

@INPROCEEDINGS{Ewald2009a,
  author = {Ewald, Roland and Leye, Stefan and Uhrmacher, Adelinde M},
  title = {An Efficient and Adaptive Mechanism for Parallel Simulation Replication},
  booktitle = {Proceedings of the 23rd ACM/IEEE/SCS Workshop on Principles of Advanced
	and Distributed Simulation (PADS)},
  year = {2009},
  pages = {104-113},
  organization = {IEEE},
  publisher = {IEEE Conference Publishing Services},
  abstract = {Simulation replication is a necessity for all stochastic simulations.
	Its efficient execution is particularly important when additional
	techniques are used on top, such as optimization or sensitivity analysis.
	One way to improve replication efficiency is to ensure that the best
	configuration of the simulation system is used for execution. A selection
	of the best configuration is possible when the number of required
	replications is sufficiently high, even without any prior knowledge
	on simulator performance or problem instance. We present an adaptive
	replication mechanism that combines portfolio theory with reinforcement
	learning: it adapts itself to the given problem instance at runtime
	and can be restricted to an efficient algorithm portfolio.},
  online = {http://dx.doi.org/10.1109/PADS.2009.11}
}

@ARTICLE{Ewald2007,
  author = {Ewald, Roland and Maus, Carsten and Rolfs, Arndt and Uhrmacher, Adelinde
	M.},
  title = {Discrete Event Modeling and Simulation in Systems Biology},
  journal = {Journal of Simulation},
  year = {2007},
  volume = {1},
  pages = {81--96},
  number = {2},
  abstract = {With Systems Biology, a promising new application area for modeling
	and simulation emerges. Today's biologists are facing huge amounts
	of data delivered at different levels of detail by a multitude of
	advanced experimentation techniques. The Systems Biology approach
	copes with this information by cycling through phases of forming
	hypothesis, constructing models, experimenting with or analyzing
	these models, and validating the findings by wet-lab experiments.
	A crucial point is therefore the way in which the knowledge about
	a system is formalized, i.e., how a biological system is described
	as this constrains the perception of the system as well as scope
	of possible answers the model might provide. In this article, we
	compare different discrete-event modeling formalisms (Petri Nets,
	Stochastic Pi-Calculus , StateCharts, and Devs) regarding their applicability
	to a cell biological system of current research interest, the Wnt
	signaling pathway. We then introduce the popular Gillespie algorithm,
	which is the foundation of many discrete-event simulators for molecular-biological
	systems, and elaborate on some interesting extensions.},
  doi = {10.1057/palgrave.jos.4250018},
  online = {http://dx.doi.org/10.1057/palgrave.jos.4250018}
}

@INPROCEEDINGS{Ewald2008a,
  author = {Ewald, Roland and Rössel, Johannes and Himmelspach, Jan and Uhrmacher,
	Adelinde M.},
  title = {A Plug-in-based Architecture for Random Number Generation in Simulation
	Systems},
  booktitle = {Proceedings of the 2008 Winter Simulation Conference},
  year = {2008},
  editor = {Mason, S. J. and Hill, R. R. and Moench, L. and Rose, O.},
  pages = {836-844},
  publisher = {IEEE Computer Society},
  abstract = {Simulations often depend heavily on random numbers, yet the impact
	of random number generators is recognized seldom. The generation
	of random numbers for simulations is not trivial, as the quality
	of each algorithm depends on the simulation scenario. Therefore,
	simulation environments for large-scale experimentation with safety-critical
	models require a reliable mechanism to cope with this aspect. We
	show how to address this problem by realizing a random number generation
	architecture for a general-purpose simulation system. It provides
	various random number generators (RNGs), probability distributions,
	and RNG tests. It is open to future additions, which allows the assessment
	of new generators in a simulation context and the re-validation of
	past simulation studies. We present a short example that illustrates
	why the features of such an architecture are essential for getting
	valid results.},
  doi = {10.1109/WSC.2008.4736147},
  online = {http://www.informs-sim.org/wsc08papers/100.pdf}
}

@INPROCEEDINGS{Ewald2010a,
  author = {Ewald, Roland and Schulz, René and Uhrmacher, Adelinde M},
  title = {Selecting Simulation Algorithm Portfolios by Genetic Algorithms},
  booktitle = {IEEE Workshop on Principles of Advanced and Distributed Simulation
	(PADS)},
  year = {2010},
  pages = {48--56},
  organization = {IEEE},
  publisher = {IEEE CPS},
  abstract = {An algorithm portfolio is a set of algorithms that are bundled together
	for increased overall performance. While being mostly applied to
	computationally hard problems so far, we investigate portfolio selection
	for simulation algorithms and focus on their application to adaptive
	simulation replication. Since the portfolio selection problem is
	itself hard to solve, we introduce a genetic algorithm to select
	the most promising portfolios from large sets of simulation algorithms.
	The effectiveness of this mechanism is evaluated by data from both
	a realistic performance study and a dedicated test environment.},
  online = {http://dx.doi.org/10.1109/PADS.2010.5471673}
}

@INPROCEEDINGS{Ewald2009,
  author = {Ewald, Roland and Uhrmacher, Adelinde and Saha, Kaustav},
  title = {Data Mining for Simulation Algorithm Selection},
  booktitle = {Proceedings of the 2nd International Conference on Simulation Tools
	and Techniques (SIMUTools)},
  year = {2009},
  publisher = {ICST},
  abstract = {While simulationists devise ever more efficient simulation algorithms
	for specific applications and infrastructures, the problem of automatically
	selecting the most appropriate one for a given problem has received
	little attention so far. One reason for this is the overwhelming
	amount of performance data that has to be analyzed for deriving suitable
	selection mechanisms. We address this problem with a framework for
	data mining on simulation performance data, which enables the evaluation
	of various data mining methods in this context. Such an evaluation
	is essential, as there is no best data mining algorithm for all kinds
	of simulation performance data. Once an effective data mining approach
	has been identified for a specific class of problems, its results
	can be used to select efficient algorithms for future simulation
	problems. This paper covers the components of the framework, the
	integration of external tools, and the re-formulation of the algorithm
	selection problem from a data mining perspective. Basic data mining
	strategies for algorithm selection are outlined, and a sample algorithm
	selection problem from Computational Biology is presented.},
  doi = {http://dx.doi.org/%2010.4108/ICST.SIMUTOOLS2009.5659},
  online = {http://eudl.eu/pdf/10.4108/ICST.SIMUTOOLS2009.5659}
}

@INPROCEEDINGS{Ewald2009c,
  author = {Ewald, Roland and Uhrmacher, Adelinde M.},
  title = {Automating the Runtime Performance Evaluation of Simulation Algorithms},
  booktitle = {Proceedings of the 2009 Winter Simulation Conference},
  year = {2009},
  editor = {Rossetti, M. D. and Hill, R. R. and Johansson, B. and Dunkin, A.
	and Ingalls, R. G.},
  pages = {1079--1091},
  publisher = {IEEE Computer Society},
  abstract = {Simulation algorithm implementations are usually evaluated by experimental
	performance analysis. To conduct such studies is a challenging and
	time-consuming task, as various impact factors have to be controlled
	and the resulting algorithm performance needs to be analyzed. This
	problem is aggravated when it comes to comparing many alternative
	implementations for a multitude of benchmark model setups. We present
	an architecture that supports the automated execution of performance
	evaluation experiments on several levels. Desirable benchmark model
	properties are motivated, and the quasi-steady state property of
	such models is exploited for simulation end time calibration, a simple
	technique to save computational effort in simulator performance comparisons.
	The overall mechanism is quite flexible and can be easily adapted
	to the various requirements that different kinds of performance studies
	impose. It is able to speed up performance experiments significantly,
	which is shown by a simple performance study.},
  online = {http://www.informs-sim.org/wsc09papers/102.pdf},
  url = {http://dx.doi.org/10.1109/WSC.2009.5429710}
}

@ARTICLE{Ewald2014,
  author = {Ewald, Roland and Uhrmacher, Adelinde M.},
  title = {SESSL: A Domain-Specific Language for Simulation Experiments},
  journal = {ACM Transactions on Modeling and Computer Simulation},
  year = {2014},
  volume = {24},
  number = {2},
  month = {Februar},
  abstract = {This paper introduces SESSL (Simulation Experiment Specification
	via a Scala Layer), an embedded domain-specific language
	for simulation experiments. It serves as an additional software layer
	between users and simulation systems and is implemented in Scala.
	SESSL supports multiple simulation systems and offers various features,
	e.g., for experiment design, performance analysis, result reporting,
	and simulation-based optimization. It supports 'cutting-edge' experiments
	by allowing to add custom code, enables a reuse of functionality
	across simulation systems, and improves the reproducibility of simulation
	experiments.},
  doi = {http://dx.doi.org/10.1145/2567895},
  online = {http://dl.acm.org/authorize?6984565},
  preprint = {docs/2014_Ewald_SESSL.pdf}
}

@MISC{Ewald2012,
  author = {Ewald, Roland and Uhrmacher, Adelinde M.},
  title = {Setting up Simulation Experiments with SESSL},
  year = {2012},
  note = {Poster},
  abstract = {Setting up simulation experiments is hard, even more so as simulation
	systems usually offer only custom interfaces for this task (e.g.,
	a graphical user interface or a programming interface). This steepens
	the learning curve for experimenters, who have to get accustomed
	with the idiosyncrasy of each simulation system they want to experiment
	with. It also makes cross-validation experiments between simulation
	systems cumbersome, since the same experiment needs to be set up
	for each system from scratch. In the following, we give a brief overview
	of SESSL, a domain-specific language for simulation experiments.
	SESSL addresses these issues by providing a common interface to set
	up simulation experiments in a more declarative manner, i.e., specifying
	what to do, not how to do it. Therefore, SESSL can also be used for
	documenting and reproducing simulation experiments.},
  abstractonline = {http://informs-sim.org/wsc12papers/includes/files/pos104.pdf},
  booktitle = {Proceedings of the 2012 Winter Simulation Conference},
  pages = {379:1--379:2},
  url = {http://dl.acm.org/citation.cfm?id=2429759.2430254}
}

@ARTICLE{Haack2015,
  author = {Haack, Fiete and Lemcke, Heiko and Ewald, Roland and Rharass, Tareck and Uhrmacher, Adelinde M},
  title = {Spatio-temporal model of endogenous ROS and raft-dependent Wnt/beta-catenin signaling driving cell fate commitment in human neural progenitor cells},
  year = {2015},
  month = {March},
  day = {20},
  abstract = {Canonical WNT/beta-catenin signaling is a central pathway in embryonic  development, but it is also connected to a number of cancers and  developmental disorders. Here we apply a combined in-vitro and in-silico  approach to investigate the spatio-temporal regulation of WNT/beta-catenin  signaling during the early neural differentiation process of human  neural progenitors cells (hNPCs), which form a new prospect for  replacement therapies in the context of neurodegenerative diseases.  Experimental measurements indicate a second signal mechanism, in  addition to canonical WNT signaling, being involved in the regulation of  nuclear beta-catenin levels during the cell fate commitment phase of  neural differentiation. We find that the biphasic activation of  beta-catenin signaling observed experimentally can only be explained  through a model that combines Reactive Oxygen Species (ROS) and raft  dependent WNT/beta-catenin signaling. Accordingly after initiation of  differentiation endogenous ROS activates DVL in a redox-dependent manner  leading to a transient activation of down-stream beta-catenin signaling,  followed by continuous auto/paracrine WNT signaling, which crucially  depends on lipid rafts. Our simulation studies further illustrate the  elaborate spatio-temporal regulation of DVL, which, depending on its  concentration and localization, may either act as direct inducer of the  transient ROS/beta-catenin signal or as amplifier during continuous  auto-/parcrine WNT/beta-catenin signaling. In addition we provide the first  stochastic computational model of WNT/beta-catenin signaling that combines  membrane-related and intracellular processes, including lipid  rafts/receptor dynamics as well as WNT- and ROS-dependent beta-catenin activation. The model's predictive ability is demonstrated under a wide  range of varying conditions for in-vitro and in-silico reference data  sets. Our in-silico approach is realized in a multi-level rule-based  language, that facilitates the extension and modification of the model.  Thus, our results provide both new insights and means to further our  understanding of canonical WNT/beta-catenin signaling and the role of ROS  as intracellular signaling mediator.},
  journal = {PLOS Computational Biology},
  volume = {11},
  number = {3},
  pages = {e1004106}
  doi = {http://dx.doi.org/10.1371/journal.pcbi.1004106},
  online = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004106}
}

@ARTICLE{Helms2015,
  author = {Helms, Tobias and Ewald, Roland and Rybacki, Stefan and Uhrmacher,
	Adelinde M},
  title = {Automatic Runtime Adaptation for Component-Based Simulation Algorithms},
  journal = {ACM Transactions on Modeling and Computer Simulation},
  year = {2015},
  month = {October},
  pages = {1-24},
  number = {1},
  volume = {26},
  publisher = {ACM},
  abstract = {The state and structure of a model may vary during a simulation and, thus, also its computational demands. Adapting simulation algorithms to these demands at runtime can therefore improve their performance. While this is a general and cross-cutting concern, only few simulation systems offer reusable support for this kind of runtime adaptation. We present a flexible and generic mechanism for the runtime adaptation of component-based simulation algorithms.Itencapsulates simulation algorithms applicable to agiven problem and employs reinforcement learning to explore the algorithms' performance during a simulation run. We evaluate our approach on a modeling formalism from computational biology and on a benchmark model defined in PDEVS, thereby investigating a broad range of options for improving its learning capabilities.},
  doi = {http://dx.doi.org/10.1145/2821509},
  online = {http://dl.acm.org/authorize?N02788}
}

@INPROCEEDINGS{Helms2013,
  author = {Helms, Tobias and Ewald, Roland and Rybacki, Stefan and Uhrmacher,
	Adelinde M},
  title = {A Generic Adaptive Simulation Algorithm for Component-based Simulation
	Systems},
  booktitle = {Proceedings of the 2013 ACM SIGSIM Conference on Principles of Advanced
	Discrete Simulation (PADS)},
  year = {2013},
  pages = {11-22},
  publisher = {ACM},
  abstract = {The state of a model may strongly vary during simulation, and with
	it also the simulation's computational demands. Adapting the simulation
	algorithm to these demands at runtime can therefore improve the overall
	performance. Although this is a general and cross-cutting concern,
	only few simulation systems offer re-usable support for this kind
	of runtime adaptation. We present a flexible and generic mechanism
	for the runtime adaptation of component-based simulation algorithms.
	It encapsulates simulation algorithms applicable to a given problem
	and employs reinforcement learning to explore the algorithms' suitability
	during a simulation run. We evaluate the approach by executing models
	from two modeling formalisms used in computational biology.},
  doi = {http://dx.doi.org/10.1145/2486092.2486095},
  online = {http://dl.acm.org/authorize?6826483}
}

@MISC{Helms2012,
  author = {Helms, Tobias and Rybacki, Stefan and Ewald, Roland and Uhrmacher,
	Adelinde M},
  title = {An Adaptive Simulator for ML-Rules},
  year = {2012},
  note = {Poster },
  abstract = {Even the most carefully configured simulation algorithm may perform
	badly unless its configuration is adapted to the dynamics of the
	model. To overcome this problem, we apply methods from reinforcement
	learning to continuously re-configure an ML-Rules simulator at runtime.
	ML-Rules is a rule-based modeling language primarily targeted at
	multi-level microbiological systems. Our results show that, for models
	with sufficiently diverse dynamics, an adaptation of the simulator
	configuration may even outperform the best-performing non-adaptive
	configuration (which is typically unknown anyhow).},
  abstractonline = {http://www.informs-sim.org/wsc12papers/includes/files/pos162.pdf},
  booktitle = {Proceedings of the 2012 Winter Simulation Conference}
}

@INPROCEEDINGS{Himmelspach2010,
  author = {Himmelspach, Jan and Ewald, Roland and Leye, Stefan and Uhrmacher,
	Adelinde M},
  title = {Enhancing the Scalability of Simulations by Embracing Multiple Levels
	of Parallelization},
  booktitle = {Proceedings of the 2010 International Workshop on High Performance
	Computational Systems Biology},
  year = {2010},
  publisher = {IEEE CPS},
  abstract = {Current and upcoming architectures of desktop and high performance
	computers offer increasing means for parallel execution. Since the
	computational demands induced by ever more realistic models increase
	steadily, this trend is of growing importance for systems biology.
	Simulations of these models may involve the consideration of multiple
	parameter combinations, their replications, data collection, and
	data analysis—all of which offer different opportunities for parallelization.
	We present a brief theoretical analysis of these opportunities in
	order to show their potential impact on the overall computation time.
	The benefits of using more than one opportunity for parallelization
	are illustrated by a set of benchmark experiments, which furthermore
	show that parallelizability should be exploited in a flexible manner
	to achieve speedup.},
  online = {http://dx.doi.org/10.1109/PDMC-HiBi.2010.17}
}

@INPROCEEDINGS{Himmelspach2007b,
  author = {Himmelspach, Jan and Ewald, Roland and Leye, Stefan and Uhrmacher,
	Adelinde M.},
  title = {Parallel and Distributed Simulation of Parallel DEVS Models},
  booktitle = {Proceedings of the SpringSim '07, DEVS Integrative M\&S Symposium},
  year = {2007},
  pages = {249--256},
  publisher = {SCS},
  abstract = {Distributed simulation can speed up the execution of models significantly.
	We introduce a new simulation algorithm and present partitioning
	and load balancing techniques that are tailored to the efficient
	distributed execution of PDEVS. We base our elaborations on the idea
	of minimizing inter-processor communication, since this is a major
	bottleneck in distributed PDEVS simulation. Additionally, experimental
	results are provided which compare the performance of this new approach
	to alternative algorithms.},
  online = {http://portal.acm.org/citation.cfm?id=1404680.1404720},
  url = {http://portal.acm.org/citation.cfm?id=1404680.1404720}
}

@INPROCEEDINGS{Himmelspach2008,
  author = {Himmelspach, Jan and Ewald, Roland and Uhrmacher, Adelinde M},
  title = {A Flexible and Scalable Experimentation Layer},
  booktitle = {Proceedings of the 2008 Winter Simulation Conference},
  year = {2008},
  editor = {S.J. Mason and R.R. Hill and L. Moench and O. Rose},
  abstract = {Modeling and simulation frameworks for use in different application
	domains, throughout the complete development process, and in different
	hardware environments need to be highly scalable. For achieving an
	efficient execution, different simulation algorithms and data structures
	must be provided to compute a concrete model on a concrete platform
	efficiently. The support of parallel simulation techniques becomes
	increasingly important in this context, which is due to the growing
	availability of multi-core processors and network-based computers.
	This leads to more complex simulation systems that are harder to
	configure correctly. We present an experimentation layer for the
	modeling and simulation framework JAMES II. It greatly facilitates
	the configuration and usage of the system for a user and supports
	distributed optimization, on-demand observation, and various distributed
	and non-distributed scenarios.},
  doi = {http://dx.doi.org/10.1109/WSC.2008.4736146},
  online = {http://www.informs-sim.org/wsc08papers/099.pdf}
}

@MISC{Himmelspach2008a,
  author = {Himmelspach, Jan and Röhl, Mathias and Ewald, Roland and Uhrmacher,
	Adelinde M},
  title = {Plug'n Simulate: Scalability as a Key Requirement for SOA-based M\&S?},
  year = {2008},
  note = {Position Paper},
  booktitle = {Workshop on Net-Centric M\&S}
}

@INPROCEEDINGS{Jeschke2008c,
  author = {Jeschke, Matthias and Ewald, Roland},
  title = {Large-Scale Design Space Exploration of SSA},
  booktitle = {Computational Methods in Systems Biology (CMSB 2008)},
  year = {2008},
  volume = {5307},
  series = {Lecture Notes in Computer Science},
  pages = {211--230},
  month = {October},
  publisher = {Springer Berlin / Heidelberg},
  abstract = {Stochastic simulation algorithms (SSA) are popular methods for the
	simulation of chemical reaction networks, so that various enhancements
	have been introduced and evaluated over the years. However, neither
	theoretical analysis nor empirical comparisons of single implementations
	suffice to capture the general performance of a method. This makes
	choosing an appropriate algorithm very hard for anyone who is not
	an expert in the field, especially if the system provides many alternative
	implementations. We argue that this problem can only be solved by
	thoroughly exploring the design spaces of such algorithms. This paper
	presents the results of an empirical study, which subsumes several
	thousand simulation runs. It aims at exploring the performance of
	different SSA implementations and comparing them to an approximation
	via tau-Leaping, while using different event queues and random number
	generators.},
  doi = {10.1007/978-3-540-88562-7_17},
  isbn = {978-3-540-88561-0},
  issn = {1611-3349},
  online = {http://dx.doi.org/10.1007/978-3-540-88562-7_17}
}

@ARTICLE{Jeschke2008a,
  author = {Jeschke, Matthias and Ewald, Roland and Park, Alfred and Fujimoto,
	Richard and Uhrmacher, Adelinde M.},
  title = {A Parallel and Distributed Discrete Event Approach for Spatial Cell-Biological
	Simulations},
  journal = {ACM SIGMETRICS Performance Evaluation Review},
  year = {2008},
  volume = {35},
  pages = {22--31},
  number = {4},
  month = {March},
  note = {Invited Paper},
  abstract = {As data and knowledge about cell-biological systems increases so does
	the need for simulation tools to support a hypothesis driven wet-lab
	experimentation. Discrete event simulation has received a lot of
	attention lately, however, often its application is hampered by its
	lack of performance. One solution are parallel, distributed approaches,
	however, their application is limited by the amount of parallelism
	available in the model. Recent studies have shown that spatial aspects
	are crucial for cell biological dynamics and they are also a promising
	candidate to exploit parallelism. Promises and specific requirements
	imposed by a spatial simulation of cell biological systems will be
	illuminated by a parallel and distributed variant of the Next-Subvolume
	Method (NSM), which augments the Stochastic Simulation Algorithm
	(SSA) with spatial features, and its realization in a grid-inspired
	simulation system called Aurora.},
  address = {New York, NY, USA},
  citeulike-article-id = {2801447},
  doi = {10.1145/1364644.1364652},
  issn = {0163-5999},
  online = {http://dl.acm.org/authorize?053616},
  publisher = {ACM}
}

@ARTICLE{Jeschke2011,
  author = {Jeschke, Matthias and Ewald, Roland and Uhrmacher, Adelinde M},
  title = {Exploring the Performance of Spatial Stochastic Simulation Algorithms},
  journal = {Journal of Computational Physics},
  year = {2011},
  volume = {230},
  pages = {2562-2574},
  number = {7},
  month = {April},
  abstract = {Since the publication of Gillespie's direct method, diverse methods
	have been developed to improve the performance of stochastic simulation
	methods and to enter the spatial realm. In this paper we discuss
	a spatial tau-leaping variant (Stau) that extends the basic leap
	method. Stau takes reaction and both outgoing and incoming diffusion
	events into account when calculating a leap candidate. A performance
	analysis shall reveal details on the achieved success in balancing
	speed and accuracy in comparison to other methods. However, performance
	analysis of spatial stochastic algorithms requires significant effort
	--- it is crucial to choose suitable (benchmark) models and to carefully
	define model and simulation setups that take problem and simulation
	design spaces into account.},
  online = {http://dx.doi.org/10.1016/j.jcp.2010.12.030},
  preprint = {docs/2011_Jeschke_ExploringSpatialSSAs.pdf}
}

@INPROCEEDINGS{Jeschke2008d,
  author = {Jeschke, Matthias and Park, Alfred and Ewald, Roland and Fujimoto,
	Richard and Uhrmacher, Adelinde M.},
  title = {Parallel and Distributed Spatial Simulation of Chemical Reactions},
  booktitle = {Proceedings of the 22nd ACM/IEEE/SCS Workshop on Principles of Advanced
	and Distributed Simulation (PADS)},
  year = {2008},
  pages = {51--59},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract = {The application of parallel and distributed simulation techniques
	is often limited by the amount of parallelism available in the model.
	This holds true for large-scale cell-biological simulations, a field
	that has emerged as data and knowledge concerning these systems increases
	and biologists call for tools to guide wet-lab experimentation. A
	promising approach to exploit parallelism in this domain is the integration
	of spatial aspects, which are often crucial to a model's validity.
	We describe an optimistic, parallel and distributed variant of the
	Next-Subvolume Method (NSM), a method that augments the well-known
	Gillespie Stochastic Simulation Algorithm (SSA) with spatial features.
	We discuss requirements imposed by this application on a parallel
	discrete event simulation engine to achieve efficient execution.
	First results of combining NSM and the grid-inspired simulation system
	Aurora are shown.},
  doi = {10.1109/PADS.2008.20},
  isbn = {978-0-7695-3159-5},
  online = {http://dx.doi.org/10.1109/PADS.2008.20}
}

@ARTICLE{John2008,
  author = {John, Mathias and Ewald, Roland and Uhrmacher, Adelinde M.},
  title = {A Spatial Extension to the Pi-Calculus},
  journal = {Electronic Notes in Theoretical Computer Science},
  year = {2008},
  volume = {194},
  pages = {133--148},
  number = {3},
  month = jan,
  abstract = {Spatial dynamics receive increasing attention in Systems Biology and
	require suitable modeling and simulation approaches. So far, modeling
	formalisms have focused on population-based approaches or place and
	move individuals relative to each other in space. SpacePi extends
	the [pi] calculus by time and space. [pi] processes are embedded
	into a vector space and move individually. Only processes that are
	sufficiently close can communicate. The operational semantics of
	SpacePi defines the interplay between movement, communication, and
	time-triggered events. A model describing the phototaxis of the Euglena
	micro-organism is presented as a practical example. The formalism's
	use and generality is discussed with respect to the modeling of molecular
	biological processes like diffusion, active transportation in cell
	signaling, and spatial structures.},
  doi = {10.1016/j.entcs.2007.12.010},
  notealso = {Proceedings of the First Workshop "From Biology To Concurrency and
	back (FBTC 2007)"},
  online = {http://dx.doi.org/10.1016/j.entcs.2007.12.010}
}

@ARTICLE{Leye2014,
  author = {Leye, Stefan and Ewald, Roland and Uhrmacher, Adelinde M.},
  title = {Composing Problem Solvers for Simulation Experimentation: A Case
	Study on Steady State Estimation},
  journal = {PLoS ONE},
  year = {2014},
  volume = {9 (4), e91948},
  abstract = {Simulation experiments involve various sub-tasks, e.g., parameter
	optimization, simulation execution, or output data analysis. Many
	algorithms can be applied to such tasks, but their performance depends
	on the given problem. Steady-state estimation in systems biology
	is a typical example for this: several estimators have been proposed,
	each with its own (dis-)advantages. Experimenters, therefore, must
	choose from the available options, even though they may not be aware
	of the consequences. To support those users, we propose a general
	scheme to aggregate such algorithms to so-called synthetic problem
	solvers, which exploit algorithm differences to improve overall performance.
	Our approach subsumes various aggregation mechanisms, supports automatic
	configuration from training data (\eg via ensemble learning or portfolio
	selection), and extends the plug-in system of the open source modeling
	and simulation framework James II. We show the benefits of our approach
	by applying it to steady-state estimation for cell-biological models.},
  online = {http://dx.doi.org/10.1371/journal.pone.0091948},
  timestamp = {2014.03.29}
}

@INPROCEEDINGS{Leye2008,
  author = {Leye, Stefen and Himmelspach, Jan and Jeschke, Matthias and Ewald,
	Roland and Uhrmacher, Adelinde M.},
  title = {A Grid-Inspired Mechanism for Coarse-Grained Experiment Execution},
  booktitle = {Proceedings of the 12th IEEE/ACM International Symposium on Distributed
	Simulation and Real-Time Applications (DS-RT)},
  year = {2008},
  pages = {7--16},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract = {Stochastic simulations may require many replications until their results
	are statistically significant. Each replication corresponds to a
	standalone simulation job, so that these can be computed in parallel.
	This paper presents a grid-inspired approach to distribute such independent
	jobsover a set of computing resources that host simulation services,
	all of which are managed by a central master service. Our method
	is fully integrated with alternative ways of distributed simulation
	in JAMES II, hides all execution details from the user, and supports
	the coarse-grained parallel execution of any sequential simulator
	available in JAMES II. A thorough performance analysis of the new
	execution mode illustrates its efficiency.},
  doi = {10.1109/DS-RT.2008.33},
  isbn = {978-0-7695-3425-1},
  online = {http://dx.doi.org/10.1109/DS-RT.2008.33}
}

@INPROCEEDINGS{Luboschik2012,
  author = {Luboschik, Martin and Rybacki, Stefan and Ewald, Roland and Schwarze,
	Benjamin and Schumann, Heidrun and Uhrmacher, Adelinde M.},
  title = {Interactive Visual Exploration of Simulator Accuracy: A Case Study
	for Stochastic Simulation Algorithms},
  booktitle = {Proceedings of the 2012 Winter Simulation Conference},
  year = {2012},
  note = {Invited Paper},
  abstract = {Visual Analytics offers various interesting methods to explore high
	dimensional data interactively. In this paper we investigate how
	it can be applied to support experimenters and developers of simulation
	software conducting simulation studies. In particular the usage and
	development of approximate simulation algorithms poses several practical
	problems, e.g., estimating the impact of algorithm parameters on
	accuracy or detecting faulty implementations. To address some of
	those problems, we present an approach that allows to relate configurations
	and accuracy visually and exploratory. The approach is evaluated
	by a brief case study, focusing on the accuracy of Stochastic Simulation
	Algorithms.},
  online = {http://www.informs-sim.org/wsc12papers/includes/files/inv113.pdf}
}

@INPROCEEDINGS{Martens2008a,
  author = {Martens, Alke and Himmelspach, Jan and Ewald, Roland},
  title = {Spiele und Simulation},
  booktitle = {Proceedings of the International Scientific E-Learning Baltics Conference},
  year = {2008},
  editor = {Hambach, S. and Martens, A. and Urban, B.},
  pages = {53-62},
  address = {Stuttgart},
  publisher = {Fraunhofer IRB Verlag},
  abstract = {Modellbildung und Simulation sind schon seit langer Zeit Bestandteil
	der Entwicklung von Spielen, und auch von Game-based Learning Systemen.
	Im Gegensatz zu dieser langen Tradition steht die Tatsache, dass
	Forschungen in beiden Bereichen häufig parallel läuft. In Spielen
	wird häufig nicht expliziert, wie welche Modelle entwickelt wurden
	oder welche Simulationsalgorithmen verwendet werden. In Simulationssystemen
	werden oft Testszenarien entwickelt, die spielerischen Charakter
	haben, ohne das dies notwendiger Weise die Entwicklung von Game-based
	Learning oder von Spielen voran bringt. Da Forschung in Modellbildung
	und Simulation die Spielentwicklung voran bringen kann, und umgekehrt
	Spielszenarien interessante Testumgebungen für Experimente darstellen
	können, wird in diesem Papier der Ansatz gemacht, das Feld zu strukturieren.
	Dabei werden die drei Bereiche Modellbildung und Simulation, Spiele
	und Game-based Learning betrachtet.}
}

@INPROCEEDINGS{Martens2008,
  author = {Martens, Alke and Himmelspach, Jan and Ewald, Roland },
  title = {Modeling, Simulation and Games},
  booktitle = {Workshop Proceedings der Tagungen Mensch und Computer 2008, Delfi
	2008 und Cognitive Design 2008},
  year = {2008},
  editor = {Lucke, U. and Kindsm{\"{u}}ller, M. C. and Fischer, S. and Herczeg,
	M. and Seehusen, S. },
  pages = {349--354},
  organization = {GI},
  publisher = {Logos Verlag, Berlin},
  abstract = {Using modeling and simulation techniques in game development can look
	back on a comparably long history, starting in the early 1970s. In
	contrast to this long tradition of combining games and simulations,
	it is usually not made explicit which kind of simulation is used,
	which models are fundament of the simulation, and which role the
	simulation and the models have in the game based scenario (e.g. non-player
	characters, environment, engines). This has led to a situation where
	research in modeling and simulation and development of games run
	in parallel -- it is not clear how recent research results influence
	the interwoven development of both fields. This paper will start
	with an attempt to structure both fields, and to provide for a collection
	of defined terms, which help to relate modeling and simulation approaches
	to game development.}
}

@INPROCEEDINGS{Naehring2013,
  author = {Nähring, Sebastian and Maus, Carsten and Ewald, Roland and Uhrmacher,
	Adelinde M},
  title = {From Standardized Modeling Formats to Modeling Languages and back
	--- an Exploration based on SBML and ML-Rules},
  booktitle = {Proceedings of the 2013 Winter Simulation Conference},
  year = {2013},
  abstract = {Standardized model exchange formats give practitioners the freedom
	to choose the most suitable tool and
	
	facilitate both cross-validation and reproduction of simulation results.
	On the other hand, standardization
	
	necessarily implies a compromise between the capabilities of individual
	modeling languages and a common
	
	ground of concepts and underlying assumptions of the given application
	domain. This compromise often
	
	leads to a mismatch of expressiveness between modeling language and
	exchange format, which should be
	
	resolved automatically, e.g., by offering a transformation. We explore
	the challenges of such an approach for
	
	the Systems Biology Markup Language (SBML), a well-established model
	format in systems biology, and
	
	ML-Rules, a rule-based modeling language for describing cell biological
	systems at multiple interrelated
	
	levels. Our transformation approach can be extended both in terms
	of the heuristics it employs and in
	
	terms of the modeling formalisms it supports.},
  online = {http://informs-sim.org/wsc13papers/includes/files/119.pdf}
}

@MISC{Naehring2012,
  author = {Nähring, Sebastian and Maus, Carsten and Ewald, Roland and Uhrmacher,
	Adelinde M},
  title = {Automated Transformation Between Modeling Languages with Different
	Expressiveness: Challenges and Results From a Use Case with SBML
	and ML-Rules},
  year = {2012},
  note = {Poster },
  abstract = {Automated transformation between modeling languages is often useful,
	e.g., to make tools (like simulators) based on one language applicable
	to models defined in other languages. However, several problems arise
	when the expressive powers of the modeling languages differ. We consider
	the automated transformation between models specified in the systems
	biology markup language (SBML) and ML-Rules, a rule-based multilevel
	modeling language. While both languages allow for modeling aspects
	that cannot be expressed in its counterpart and thus prevent a complete
	and fully automated transformation, it is still possible to transform
	many useful classes of models. Even more models can be transformed
	by relying on certain heuristics or user input.},
  abstractonline = {http://www.informs-sim.org/wsc12papers/includes/files/pos164.pdf},
  booktitle = {Proceedings of the 2012 Winter Simulation Conference}
}

@INPROCEEDINGS{Peng2014,
  author = {Peng, Danhua and Ewald, Roland and Uhrmacher, Adelinde M.},
  title = {Towards Semantic Model Composition via Experiments},
  booktitle = {Proceedings of the 2014 ACM SIGSIM Conference on Principles of Advanced
	Discrete Simulation (PADS)},
  year = {2014},
  online = {http://dx.doi.org/10.1145/2601381.2601394},
  preprint = {docs/2014_DanhuaPeng_SemanticComposition.pdf},
  abstract = {Unambiguous experiment descriptions are increasingly required for
	model publication, as they contain information important for reproducing
	simulation results. In the context of model composition, this information
	can be used to generate experiments for the composed model. If the
	original experiment descriptions specify which model property they
	refer to, we can then execute the generated experiments and assess
	the validity of the composed model by evaluating their results. Thereby,
	we move the attention to describing properties of a model's behavior
	and the conditions under which these hold, i.e., its semantics. We
	illuminate the potential of this concept by considering the composition
	of Lotka-Volterra models. In a first prototype realized for JAMES
	II, we use ML-Rules to describe and execute the Lotka-Volterra models
	and SESSL for specifying the original experiments. Model properties
	are described in continuous stochastic logic, and we use statistical
	model checking for their evaluation. Based on this, experiments to
	check whether these properties hold for the composed model are automatically
	generated and executed.}
}

@MISC{Schuetzel2013,
  author = {Schützel, Johannes and Ewald, Roland and Uhrmacher, Adelinde M},
  title = {A General Foundation for Formalism-Specific Instrumentation Languages},
  year = {2013},
  note = {Poster },
  abstract = {Experimenters need to configure the data collection performed during
	a simulation run, as this avoids overly large output data sets and
	the overhead of collecting them. Instrumentation languages address
	this problem by allowing experimenters to specify the data of interest.
	Such languages typically focus on a specific modeling formalism.
	While this allows for a more expressive syntax, it also prohibits
	their application to other formalisms. To resolve this trade-off,
	we propose a formalism-independent model of the instrumentation semantics
	and use it as a basis for developing embedded domain-specific languages
	(DSLs). Our instrumentation DSLs share common code, allow to add
	formalism-specific syntax, and are easy to extend.},
  abstractonline = {http://informs-sim.org/wsc13papers/includes/files/396.pdf},
  booktitle = {Proceedings of the 2013 Winter Simulation Conference},
  owner = {roland},
  timestamp = {2014.03.29}
}

@INCOLLECTION{Theodoropoulos2009,
  author = {Theodoropoulos, Georgios and Minson, Rob and Ewald, Roland and Lees,
	Michael},
  title = {Simulation Engines for Multi-Agent Systems},
  booktitle = {Agents, Simulation and Applications},
  publisher = {Taylor and Francis},
  year = {2009},
  editor = {Weyns, Danny and Uhrmacher, Adelinde M.},
  series = {Computational analysis, synthesis, and design of dynamic models},
  chapter = {3},
  pages = {77--105},
  note = {Book Chapter},
  isbn = {9781420070231},
  online = {http://dx.doi.org/10.1201/9781420070248.ch3}
}

@INCOLLECTION{Uhrmacher2008,
  author = {Uhrmacher, Adelinde and Himmelspach, Jan and Jeschke, Matthias and
	John, Mathias and Leye, Stefan and Maus, Carsten and Röhl, Mathias
	and Ewald, Roland},
  title = {One Modelling Formalism \& Simulator Is Not Enough! A Perspective
	for Computational Biology Based on James II},
  booktitle = {Proceedings of the 1st International Workshop on Formal Methods in
	Systems Biology},
  publisher = {Springer Berlin / Heidelberg},
  year = {2008},
  series = {Lecture Notes in Bioinformatics},
  pages = {123--138},
  abstract = {Diverse modelling formalisms are applied in Computational Biology.
	Some describe the biological system in a continuous manner, others
	focus on discrete-event systems, or on a combination of continuous
	and discrete descriptions. Similarly, there are many simulators that
	support different formalisms and execution types (e.g. sequential,
	parallel-distributed) of one and the same model. The latter is often
	done to increase efficiency, sometimes at the cost of accuracy and
	level of detail. JAMES II has been developed to support different
	modelling formalisms and different simulators and their combinations.
	It is based on a plug-in concept which enables developers to integrate
	spatial and non-spatial modelling formalisms (e.g. Stochastic Pi,
	Beta Binders, DEVS, Space Pi), simulation algorithms (e.g. variants
	of Gillespie's algorithms (including Tau Leaping and NSM), Space
	Pi simulator, parallel Beta Binders simulator) and supporting technologies
	(e.g. partitioning algorithms, data collection mechanisms, data structures,
	random number generators) into an existing framework. This eases
	method development and result evaluation in applied modelling and
	simulation as well as in modelling and simulation research.},
  doi = {10.1007/978-3-540-68413-8_9},
  journalseries = {Formal Methods in Systems Biology},
  online = {http://dx.doi.org/10.1007/978-3-540-68413-8_9},
  volumeseries = {5054}
}

@INPROCEEDINGS{Uhrmacher2007,
  author = {Uhrmacher, Adelinde M. and Ewald, Roland and John, Mathias and Maus,
	Carsten and Jeschke, Matthias and Biermann, Susanne},
  title = {Combining Micro and Macro-Modeling in DEVS for Computational Biology},
  booktitle = {Proceedings of the 2007 Winter Simulation Conference},
  year = {2007},
  pages = {871-880},
  publisher = {IEEE Press},
  abstract = {In computational biology there is an increasing need to combine micro
	and macro views of the system of interest. Therefore, explicit means
	to describe micro and macro level and the downward and upward causation
	that link both are required. Multi-Level-DEVS (or ml-DEVS) supports
	an explicit description of macro and micro level, information at
	macro level can be accessed from micro level and vice versa, micro
	models can be synchronously activated by the macro model and also
	the micro models can trigger the dynamics at macro level. To link
	both levels, different methods are combined, to those belong, value
	coupling, synchronous activations, variable ports, and invariants.
	The execution semantic of the formalism is given by an abstract simulator
	and its use is illustrated based on an small extract of the Wnt pathway.},
  doi = {10.1109/WSC.2007.4419683},
  online = {http://www.informs-sim.org/wsc07papers/102.pdf},
  url = {http://dx.doi.org/10.1109/WSC.2007.4419683}
}

@INCOLLECTION{Uhrmacher2010,
  author = {Uhrmacher, Adelinde M. and Himmelspach, Jan and Ewald, Roland},
  title = {Effective and Efficient Modeling and Simulation with DEVS Variants},
  booktitle = {Discrete-Event Modeling and Simulation: Theory and Applications},
  publisher = {Taylor and Francis},
  year = {2010},
  editor = {G. Wainer and P. Mosterman},
  note = {Book Chapter},
  isbn = {9781420072334},
  online = {http://books.google.de/books?hl=de&lr=&id=WQvzk7ZnwHkC}
}

@INPROCEEDINGS{Uhrmacher2006,
  author = {Uhrmacher, Adelinde M. and Himmelspach, Jan and Röhl, Mathias and
	Ewald, Roland },
  title = {Introducing Variable Ports and Multi-Couplings for Cell Biological
	Modeling in DEVS},
  booktitle = {Proceedings of the 2006 Winter Simulation Conference},
  year = {2006},
  editor = {L. F. Perrone and F. P. Wieland and J. Liu and B. G. Lawson and D.
	M. Nicol and R. M. Fujimoto},
  pages = {832-840},
  publisher = {IEEE Computer Society},
  abstract = {Motivated by the requirements of molecular biological applications
	we are suggesting an extension of the {D}evs formalism. {S}tarting
	with dyn{D}evs a reflective variant of {D}evs which supports dynamic
	behavior, composition, and interaction pattern, we develop rho-{D}evs.
	{D}ynamic ports and multi-couplings are introduced whose combination
	allows models to reflect significant state changes to the outside
	world and enabling or disabling certain interactions at the same
	time. {A}n abstract simulator describes the operational semantics
	of the developed formalism, and the trp operon model illustrates
	the developed ideas and concepts.},
  online = {http://www.informs-sim.org/wsc06papers/104.pdf}
}

@INPROCEEDINGS{Wang2009,
  author = {Wang, Bing and Himmelspach, Jan and Ewald, Roland and Yao, Yiping
	and Uhrmacher, Adelinde M.},
  title = {Experimental Analysis of Logical Process Simulation Algorithms in
	JAMES II},
  booktitle = {Proceedings of the 2009 Winter Simulation Conference},
  year = {2009},
  editor = {Rossetti, M. D. and Hill, R. R. and Johansson, B. and Dunkin, A.
	and Ingalls, R. G.},
  pages = {1167--1179},
  publisher = {IEEE Computer Science},
  abstract = {The notion of logical processes is a widely used modeling paradigm
	in parallel and distributed discrete-event simulation. Yet, the comparison
	among different simulation algorithms for LP models still remains
	difficult. Most simulation systems only provide a small subset of
	available algorithms, which are usually selected and tuned towards
	specific applications. Furthermore, many modeling and simulation
	frameworks blur the boundary between model logic and simulation algorithm,
	which hampers the extensibility and the comparability. Based on the
	general-purpose modeling and simulation framework JAMES II, which
	has already been used for experiments with algorithms several times,
	we present an environment for the experimental analysis of simulation
	algorithms for logical processes. It separates model from simulator
	concepts, is extensible (in regards to the benchmark models, the
	algorithms used, etc.), and facilitates a fair comparison of algorithms.},
  doi = {http://dx.doi.org/10.1109/WSC.2009.5429633},
  online = {http://www.informs-sim.org/wsc09papers/110.pdf}
}

@MISC{Wang2009Poster,
  author = {Wang, Bing and Himmelspach, Jan and Ewald, Roland and Yao, Yiping
	and Uhrmacher, Adelinde M},
  title = {An Experimental Analysis Environment for Logical Process Simulation
	Algorithms},
  year = {2009},
  note = {Poster},
  abstract = {The notion of logical processes (LPs) is a widely used modeling paradigm
	in parallel and distributed discrete-event simulation (PDES). Nevertheless
	the comparison among different simulation algorithms for LP models
	still remains difficult: there are too many combinations of algorithms
	to be explored, often simulation systems only provide a small subset
	of available algorithms, and many m\&amp;s frameworks blur the boundary
	between model logic and simulation algorithm, which hampers extensibility
	and comparability. We present an environment for the experimental
	analysis of simulation algorithms for logical processes. It separates
	between model and simulator, is extensible, and facilitates a fair
	comparison of algorithms. We illustrate the functioning of the environment
	by presenting experimental results for well-known simulation algorithms
	and a benchmark model.},
  booktitle = {Proceedings of the 2nd International ICST Conference on Simulation
	Tools and Techniques (SIMUTools)},
  online = {http://dx.doi.org/10.4108/ICST.SIMUTOOLS2009.5678}
}

@INPROCEEDINGS{Wienss2013,
  author = {Wienß, Jonathan and Stein, Michael and Ewald, Roland},
  title = {Evaluating Simulation Software Components with Player Rating Systems},
  booktitle = {Proceedings of the 6th International ICST Conference on Simulation
	Tools and Techniques (SIMUTools)},
  year = {2013},
  organization = {ICST},
  abstract = {In component-based simulation systems, simulation runs are usually
	executed by combinations of distinct components, each solving a particular
	sub-task. If multiple components are available for a given sub-task
	(e.g., different event queue implementations), a simulation system
	may rely on an automatic selection mechanism, on a user decision,
	or --- if neither is available --- on a predefined default component.
	However, deciding upon a default component for each kind of sub-task
	is difficult: such a component should work well across various application
	domains and various combinations with other components. Furthermore,
	the performance of individual components cannot be evaluated easily,
	since performance is typically measured for component combinations
	as a whole (e.g., the execution time of a simulation run). Finally,
	the selection of default components should be dynamic, as new and
	potentially superior components may be deployed to the system over
	time. We illustrate how player rating systems for team-based games
	can solve the above problems and evaluate our approach with an implementation
	of the TrueSkill(tm) rating system (Herbrich et al, 2007), applied
	in the context of the open-source modeling and simulation framework
	JAMES II. We also show how such systems can be used to steer performance
	analysis experiments for component ranking. Paper and talk slides
	are available online.},
  online = {http://dl.acm.org/citation.cfm?id=2512740}
}

